{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universidade de Caxias do Sul\n",
    "### Área de Exatas e Engenharias\n",
    "### Disciplina: Inteligência Computacional\n",
    "### Profa. Carine G. Webber\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importação das Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "import sklearn.metrics as metric\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Definição do conjunto de dados de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treino=[  [1, 1], \n",
    "            [1, 0],\n",
    "            [0, 1],\n",
    "            [0, 0]\n",
    "         ]\n",
    "y_treino=[1, \n",
    "          1,\n",
    "          1,\n",
    "          0\n",
    "          ]\n",
    "X_teste=X_treino\n",
    "y_teste=y_treino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Exemplo usando o modelo Perceptron\n",
    "### método de treino => fit(dados_treino,classes_treino)\n",
    "### método de teste => predict(classes_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "ptn = Perceptron(max_iter=500,tol=0.001)                    \n",
    "ptn.fit(X_treino, y_treino)                    \n",
    "y_pred=ptn.predict(X_teste)                      \n",
    "print(y_pred)                                                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Cálculo da acurácia do classificador Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acurácia= 1.0\n"
     ]
    }
   ],
   "source": [
    "accuracy=metric.accuracy_score(y_teste, y_pred, normalize=True)\n",
    "print('acurácia=',accuracy)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ponto de intersecção : intercept_\n",
    "## Pesos das conexões : coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.] [[2. 2.]]\n"
     ]
    }
   ],
   "source": [
    "print(ptn.intercept_, ptn.coef_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Uso de uma Rede Neural Perceptron Multi-camadas (MLP)\n",
    "## Classe : MLPClassifier\n",
    "### Parâmetros: \n",
    "#### Solver\n",
    "#### Camadas escondidas\n",
    "#### Função de ativação\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0]\n",
      "acuracy= 1.0\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(1,1), activation='logistic') \n",
    "mlp.fit(X_treino, y_treino)                        \n",
    "y_pred=mlp.predict(X_teste)                        \n",
    "print(y_pred)                                    \n",
    "accuracy=metric.accuracy_score(np.array(y_teste).flatten(), np.array(y_pred).flatten(), normalize=True)\n",
    "print('acuracy=',accuracy)                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Verifique os pesos das conexões entre os neurônios\n",
    "#### Observe que a cada execução do passo 5, os pesos mudam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 1), (1, 1), (1, 1)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[4.14760407],\n",
       "        [4.1564221 ]]), array([[8.13253145]]), array([[14.87565758]])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print([coef.shape for coef in mlp.coefs_])  \n",
    "mlp.coefs_                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. TAREFAS \n",
    "\n",
    "- a) modifique os dados (X_treino, y_treino, X_teste)\n",
    "- b) altere dos dados de binários para bipolares {-1, +1}\n",
    "- c) altere a camada escondida do MLP: número de camadas (int) ou tamanho (n,m)\n",
    "- d) altere o parâmetro solver do MLP: {'lbfgs', 'sgd', 'adam'}\n",
    "- e) altere a função de ativação do MLP: {'identity', 'logistic', 'tanh', 'relu'}, default 'relu'\n",
    "\n",
    "Orientação:\n",
    " - verifique a acurácia de cada predição\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primeira tarefa: OU Bipolar\n",
    "Troque as entradas {0, 1} por valores bipolares {-1, +1}. \n",
    "Utilize os dados e execute o Perceptron e o MLP, conforme o exemplo (4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  1 -1]\n",
      "acurácia Perceptron: 1.0\n",
      "\n",
      "[ 1  1  1 -1]\n",
      "acurácia MLP: 1.0\n"
     ]
    }
   ],
   "source": [
    "X_treino=[[1, 1], \n",
    "            [1, -1],\n",
    "            [-1, 1],\n",
    "            [-1, -1]\n",
    "           ]\n",
    "y_treino=[1, \n",
    "            1,\n",
    "            1,\n",
    "            -1\n",
    "           ]\n",
    "X_teste=X_treino\n",
    "y_teste=y_treino\n",
    "\n",
    "ptn = Perceptron(max_iter=500,tol=0.001)                    \n",
    "ptn.fit(X_treino, y_treino)                    \n",
    "y_pred=ptn.predict(X_teste)                      \n",
    "print(y_pred) \n",
    "accuracy=metric.accuracy_score(y_teste, y_pred, normalize=True)\n",
    "print('acurácia Perceptron:',accuracy)    \n",
    "print()\n",
    "\n",
    "mlp = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(3,3), activation='relu') \n",
    "mlp.fit(X_treino, y_treino)                        \n",
    "y_pred=mlp.predict(X_teste)                        \n",
    "print(y_pred)                                    \n",
    "accuracy=metric.accuracy_score(np.array(y_teste).flatten(), np.array(y_pred).flatten(), normalize=True)\n",
    "print('acurácia MLP:',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segunda tarefa: E Binário\n",
    "Utilize os dados e execute o Perceptron e o MLP, conforme o exemplo (4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0]\n",
      "acurácia Perceptron: 1.0\n",
      "\n",
      "[1 0 0 0]\n",
      "acurácia MLP: 1.0\n"
     ]
    }
   ],
   "source": [
    "X_treino=[[1, 1], \n",
    "            [1, 0],\n",
    "            [0, 1],\n",
    "            [0, 0]\n",
    "           ]\n",
    "y_treino=[1, \n",
    "            0,\n",
    "            0,\n",
    "            0\n",
    "           ]\n",
    "X_teste=X_treino\n",
    "y_teste=y_treino\n",
    "\n",
    "ptn = Perceptron(max_iter=500,tol=0.001)                    \n",
    "ptn.fit(X_treino, y_treino)                    \n",
    "y_pred=ptn.predict(X_teste)                      \n",
    "print(y_pred) \n",
    "accuracy=metric.accuracy_score(y_teste, y_pred, normalize=True)\n",
    "print('acurácia Perceptron:',accuracy)    \n",
    "print()\n",
    "\n",
    "mlp = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(3,3), activation='relu') \n",
    "mlp.fit(X_treino, y_treino)                        \n",
    "y_pred=mlp.predict(X_teste)                        \n",
    "print(y_pred)                                    \n",
    "accuracy=metric.accuracy_score(np.array(y_teste).flatten(), np.array(y_pred).flatten(), normalize=True)\n",
    "print('acurácia MLP:',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Terceira tarefa: E Bipolar\n",
    "Modifique os dados binários da segunda tarefa para dados bipolares. \n",
    "Utilize os dados e execute o Perceptron e o MLP.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  1 -1]\n",
      "acurácia Perceptron: 1.0\n",
      "\n",
      "[ 1  1  1 -1]\n",
      "acurácia MLP: 1.0\n"
     ]
    }
   ],
   "source": [
    "X_treino=[[1, 1], \n",
    "            [1, -1],\n",
    "            [-1, 1],\n",
    "            [-1, -1]\n",
    "           ]\n",
    "y_treino=[1, \n",
    "            1,\n",
    "            1,\n",
    "            -1\n",
    "           ]\n",
    "X_teste=X_treino\n",
    "y_teste=y_treino\n",
    "\n",
    "ptn = Perceptron(max_iter=500,tol=0.001)                    \n",
    "ptn.fit(X_treino, y_treino)                    \n",
    "y_pred=ptn.predict(X_teste)                      \n",
    "print(y_pred) \n",
    "accuracy=metric.accuracy_score(y_teste, y_pred, normalize=True)\n",
    "print('acurácia Perceptron:',accuracy)    \n",
    "print()\n",
    "\n",
    "mlp = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(3,3), activation='relu') \n",
    "mlp.fit(X_treino, y_treino)                        \n",
    "y_pred=mlp.predict(X_teste)                        \n",
    "print(y_pred)                                    \n",
    "accuracy=metric.accuracy_score(np.array(y_teste).flatten(), np.array(y_pred).flatten(), normalize=True)\n",
    "print('acurácia MLP:',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quarta tarefa: dois neurônios de saída\n",
    "Utilize o MLP para treinar e predizer o seguinte dataset. O que você observou ? Interprete a resposta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]]\n",
      "acurácia MLP: 1.0\n",
      "Após a terceira execução a predição ficou igual aos dados de treino, acredito exista uma falta de diversificação aos dados\n"
     ]
    }
   ],
   "source": [
    "X_treino=[[1, 1], \n",
    "            [1, 0],\n",
    "            [0, 1],\n",
    "            [0, 0]\n",
    "           ]\n",
    "y_treino=[[1, 1], \n",
    "            [1, 1],\n",
    "            [1, 1],\n",
    "            [0, 1]\n",
    "           ]\n",
    "X_teste=X_treino\n",
    "y_teste=y_treino\n",
    "\n",
    "mlp = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(5,2), activation='relu') \n",
    "mlp.fit(X_treino, y_treino)                        \n",
    "y_pred=mlp.predict(X_teste)                        \n",
    "print(y_pred)                                    \n",
    "accuracy=metric.accuracy_score(np.array(y_teste).flatten(), np.array(y_pred).flatten(), normalize=True)\n",
    "print('acurácia MLP:',accuracy)\n",
    "print('Após a terceira execução a predição ficou igual aos dados de treino, acredito exista uma falta de diversificação aos dados')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quinta tarefa: XOR\n",
    "Use o MLP para resolver o problema XOR Booleano. Como melhorar a acurácia? Qual configuração mínima de camadas escondidas é necessária para tornar a acurácia 1.0 (100% de acerto)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1]\n",
      "acurácia MLP: 1.0\n",
      "Para melhorar a acurácia podemos alterar as camadas escondidas.\n",
      "A configuração com (6,6) tornou a acurácia 1\n"
     ]
    }
   ],
   "source": [
    "X_treino=[[1, 1], \n",
    "            [1, 0],\n",
    "            [0, 1],\n",
    "            [0, 0]\n",
    "           ]\n",
    "y_treino=[1, \n",
    "            0,\n",
    "            0,\n",
    "            1\n",
    "           ]\n",
    "X_teste=X_treino\n",
    "y_teste=y_treino\n",
    "\n",
    "mlp = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(6,6), activation='relu') \n",
    "mlp.fit(X_treino, y_treino)                        \n",
    "y_pred=mlp.predict(X_teste)                        \n",
    "print(y_pred)                                    \n",
    "accuracy=metric.accuracy_score(np.array(y_teste).flatten(), np.array(y_pred).flatten(), normalize=True)\n",
    "print('acurácia MLP:',accuracy)\n",
    "print('Para melhorar a acurácia podemos alterar as camadas escondidas.')\n",
    "print('A configuração com (6,6) tornou a acurácia 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sexta tarefa: Tautologia\n",
    "Treine o MLP para resolver o problema da Tautologia binária. Observe o comportamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treino=[[1, 1], \n",
    "            [1, 0],\n",
    "            [0, 1],\n",
    "            [0, 0]\n",
    "           ]\n",
    "y_treino=[1, \n",
    "            1,\n",
    "            1,\n",
    "            1\n",
    "           ]\n",
    "X_teste=X_treino\n",
    "y_teste=y_treino\n",
    "\n",
    "mlp = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(4,2), activation='relu') \n",
    "mlp.fit(X_treino, y_treino)                        \n",
    "y_pred=mlp.predict(X_teste)                        \n",
    "print(y_pred)                                    \n",
    "accuracy=metric.accuracy_score(np.array(y_teste).flatten(), np.array(y_pred).flatten(), normalize=True)\n",
    "print('acurácia MLP:',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sétima tarefa: XNOR\n",
    "Use o MLP para resolver o problema XNOR Booleano. Como melhorar a acurácia? Qual configuração mínima de camadas escondidas é necessária para tornar a acurácia 1.0 (100% de acerto)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0]\n",
      "acurácia MLP: 1.0\n",
      "Para melhorar a acurácia podemos alterar as camadas escondidas.\n",
      "A configuração com (6,8) tornou a acurácia 1\n"
     ]
    }
   ],
   "source": [
    "X_treino=[[1, 1], \n",
    "            [1, 0],\n",
    "            [0, 1],\n",
    "            [0, 0]\n",
    "           ]\n",
    "y_treino=[0, \n",
    "            1,\n",
    "            1,\n",
    "            0\n",
    "           ]\n",
    "X_teste=X_treino\n",
    "y_teste=y_treino\n",
    "\n",
    "mlp = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(6,8), activation='relu') \n",
    "mlp.fit(X_treino, y_treino)                        \n",
    "y_pred=mlp.predict(X_teste)                        \n",
    "print(y_pred)                                    \n",
    "accuracy=metric.accuracy_score(np.array(y_teste).flatten(), np.array(y_pred).flatten(), normalize=True)\n",
    "print('acurácia MLP:',accuracy)\n",
    "print('Para melhorar a acurácia podemos alterar as camadas escondidas.')\n",
    "print('A configuração com (6,8) tornou a acurácia 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oitava tarefa: Rede Neural com 3 entradas e 2 saídas\n",
    "Experimente treinar os seguintes dados usando o MLP.  Altere o solver, as camadas escondidas e a função de ativação para melhorar a acurácia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]]\n",
      "acurácia MLP: 1.0\n"
     ]
    }
   ],
   "source": [
    "X_treino=[[ 1,  1,  0], \n",
    "            [ 1, -1, -1],\n",
    "            [-1,  1,  1],\n",
    "            [-1, -1,  1],\n",
    "            [ 0,  1, -1],\n",
    "            [ 0, -1, -1],\n",
    "            [ 1,  1,  1]\n",
    "           ]\n",
    "y_treino=[[1, 0], \n",
    "            [0, 1],\n",
    "            [1, 1],\n",
    "            [1, 0],\n",
    "            [1, 0],\n",
    "            [1, 1],\n",
    "            [1, 1]\n",
    "           ]\n",
    "X_teste=X_treino\n",
    "y_teste=y_treino\n",
    "\n",
    "#altere o parâmetro solver do MLP: {'lbfgs', 'sgd', 'adam'}\n",
    "#ealtere a função de ativação do MLP: {'identity', 'logistic', 'tanh', 'relu'}, default 'relu'\n",
    "\n",
    "mlp = MLPClassifier(solver='adam', hidden_layer_sizes=(5,5), activation='tanh', max_iter=3000) \n",
    "mlp.fit(X_treino, y_treino)                        \n",
    "y_pred=mlp.predict(X_teste)                        \n",
    "print(y_pred)                                    \n",
    "accuracy=metric.accuracy_score(np.array(y_teste).flatten(), np.array(y_pred).flatten(), normalize=True)\n",
    "print('acurácia MLP:',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
